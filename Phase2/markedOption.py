import cv2
import numpy as np
import os
import json
import re

class MarkedOptionDetector:
    def __init__(self, image_path, mapped_annotations_data, output_dir):
        self.image_path = image_path
        self.image = cv2.imread(image_path) 
        if self.image is None:
            raise FileNotFoundError(f"Image not found at {image_path}. Ensure this is the deskewed image generated by optionMapping.py.")
        
        self.mapped_annotations = mapped_annotations_data
        
        # Base output directory for marked results (e.g., D:\Projects\OMR\new_abhigyan\Phase2\marked_results)
        self.output_dir = output_dir 

        # Base directory for individual option extractions (e.g., ...\marked_results\option_crops)
        self.base_option_crops_dir = os.path.join(self.output_dir, "option_crops")
        os.makedirs(self.base_option_crops_dir, exist_ok=True)

        # Directory for images with marked options superimposed (e.g., ...\marked_results\marked_superimposed)
        self.marked_superimposed_dir = os.path.join(self.output_dir, "marked_superimposed")
        os.makedirs(self.marked_superimposed_dir, exist_ok=True)

        # Directory for review images (e.g., ...\marked_results\reviews)
        self.reviews_dir = os.path.join(self.output_dir, "reviews")
        os.makedirs(self.reviews_dir, exist_ok=True)


    def _extract_question_option_bboxes(self):
        questions = {}
        options = {}

        for class_name, bbox in self.mapped_annotations.items():
            match_q = re.match(r'Q(\d+)', class_name)
            match_opt = re.match(r'(\d+)([A-D])', class_name)

            if match_q:
                q_num = int(match_q.group(1))
                questions[q_num] = bbox
            elif match_opt:
                q_num = int(match_opt.group(1))
                option_letter = match_opt.group(2)
                if q_num not in options:
                    options[q_num] = {}
                options[q_num][option_letter] = bbox
        
        # Sort options (A, B, C, D) for consistent processing
        for q_num in options:
            options[q_num] = dict(sorted(options[q_num].items()))

        return questions, options

    def _get_marked_data_from_circle(self, option_img_roi, min_pixel_intensity_threshold=90):
        gray_option = cv2.cvtColor(option_img_roi, cv2.COLOR_BGR2GRAY)
        blurred = cv2.GaussianBlur(gray_option, (5, 5), 0)

        min_dim = min(option_img_roi.shape[0], option_img_roi.shape[1])
        min_r_estimate = int(min_dim * 0.3)
        max_r_estimate = int(min_dim * 0.45)
        
        circles = cv2.HoughCircles(blurred, cv2.HOUGH_GRADIENT, dp=1.0, minDist=min_dim // 4, 
                                   param1=100, param2=20, 
                                   minRadius=min_r_estimate, maxRadius=max_r_estimate)

        circle_mask = np.zeros_like(gray_option)
        center_x, center_y, radius = -1, -1, -1 
        detected_circle = False

        if circles is not None:
            circles = np.uint16(np.around(circles))
            largest_circle = None
            max_radius = 0
            for i in circles[0, :]:
                # Filter out circles too close to the border or too small
                if i[2] > max_radius and \
                   i[0] - i[2] >= 0 and i[0] + i[2] < option_img_roi.shape[1] and \
                   i[1] - i[2] >= 0 and i[1] + i[2] < option_img_roi.shape[0]:
                    max_radius = i[2]
                    largest_circle = i
            
            if largest_circle is not None:
                center_x, center_y, radius = largest_circle[0], largest_circle[1], largest_circle[2]
                cv2.circle(circle_mask, (center_x, center_y), radius, 255, -1)
                detected_circle = True

        if not detected_circle:
            print("Warning: No prominent circle found. Analyzing central square region of ROI as fallback.")
            h, w = gray_option.shape
            square_side = min(h, w)
            x_start = (w - square_side) // 2
            y_start = (h - square_side) // 2
            circle_mask[y_start : y_start + square_side, x_start : x_start + square_side] = 255
            # For visualization, set center and radius for the fallback square
            center_x, center_y = w // 2, h // 2
            radius = square_side // 2

        masked_region = cv2.bitwise_and(blurred, blurred, mask=circle_mask)
        
        pixels_in_mask = masked_region[circle_mask == 255]
        
        if pixels_in_mask.size == 0:
            return 0.0, np.zeros_like(blurred), 255.0, False, (center_x, center_y, radius), detected_circle

        mean_intensity = np.mean(pixels_in_mask)
        is_potentially_marked_by_intensity = mean_intensity < min_pixel_intensity_threshold
        
        _, global_thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        
        thresh_binary_masked = cv2.bitwise_and(global_thresh, global_thresh, mask=circle_mask)

        kernel = np.ones((3,3), np.uint8) 
        thresh_eroded = cv2.erode(thresh_binary_masked, kernel, iterations=1)
        thresh_dilated = cv2.dilate(thresh_eroded, kernel, iterations=2) 
        
        thresh_final = cv2.bitwise_and(thresh_dilated, thresh_dilated, mask=circle_mask)

        marked_pixels_count = cv2.countNonZero(thresh_final)
        total_mask_pixels = cv2.countNonZero(circle_mask)

        fill_percentage = 0.0
        if total_mask_pixels > 0:
            fill_percentage = marked_pixels_count / total_mask_pixels

        return fill_percentage, thresh_final, mean_intensity, is_potentially_marked_by_intensity, (center_x, center_y, radius), detected_circle

    def _save_for_review(self, q_num, image_name_without_ext, questions_bboxes):
        """
        Saves the cropped image of a question to the review folder.
        """
        review_image_dir = os.path.join(self.reviews_dir, image_name_without_ext)
        os.makedirs(review_image_dir, exist_ok=True)

        if q_num in questions_bboxes:
            qx1, qy1, qx2, qy2 = questions_bboxes[q_num]

            # Ensure bbox coordinates are within image boundaries
            qx1 = max(0, qx1)
            qy1 = max(0, qy1)
            qx2 = min(self.image.shape[1], qx2)
            qy2 = min(self.image.shape[0], qy2)

            if qx2 <= qx1 or qy2 <= qy1:
                print(f"Warning: Invalid bounding box for review question Q{q_num}: ({qx1},{qy1},{qx2},{qy2}). Skipping review save.")
                return

            question_roi = self.image[qy1:qy2, qx1:qx2]
            
            if question_roi.size == 0:
                print(f"Warning: Empty ROI for review question Q{q_num}. Skipping review save.")
                return

            review_save_path = os.path.join(review_image_dir, f"Q{q_num}.jpg")
            cv2.imwrite(review_save_path, question_roi)
            print(f"  Q{q_num} sent for review. Saved to: {review_save_path}")
        else:
            print(f"Warning: Question Q{q_num} bounding box not found for review. Skipping.")


    def detect_marked_options(self, min_fill_percentage_threshold=0.35, min_pixel_intensity_threshold=90):
        questions_bboxes, options_bboxes = self._extract_question_option_bboxes()
        results = {}
        
        image_with_marked_overlays = self.image.copy()

        print("\n--- Option Analysis ---")
        print(f"Global min_fill_percentage_threshold: {min_fill_percentage_threshold:.2f}")
        print(f"Global min_pixel_intensity_threshold: {min_pixel_intensity_threshold:.1f}\n")

        base_filename = os.path.basename(self.image_path)
        name_without_ext = os.path.splitext(base_filename)[0]

        # Create image-specific subfolder for option crops
        current_option_crops_dir = os.path.join(self.base_option_crops_dir, name_without_ext)
        os.makedirs(current_option_crops_dir, exist_ok=True)

        for q_num in sorted(questions_bboxes.keys()): # Iterate through questions to ensure order
            marked_options_for_q = []
            
            if q_num in options_bboxes:
                for option_letter, bbox in options_bboxes[q_num].items():
                    x1, y1, x2, y2 = bbox
                    
                    x1 = max(0, x1)
                    y1 = max(0, y1)
                    x2 = min(self.image.shape[1], x2)
                    y2 = min(self.image.shape[0], y2)

                    if x2 <= x1 or y2 <= y1:
                        print(f"Warning: Invalid bounding box for {q_num}{option_letter}: {bbox}. Skipping.")
                        continue

                    option_img_roi = self.image[y1:y2, x1:x2]

                    if option_img_roi.size == 0:
                        print(f"Warning: Empty ROI for {q_num}{option_letter}. Skipping.")
                        continue

                    # Call the refined detection function
                    fill_percentage, thresh_img, mean_intensity, is_potentially_marked_by_intensity, circle_coords, circle_found = \
                        self._get_marked_data_from_circle(option_img_roi, min_pixel_intensity_threshold)
                    
                    # Determine if marked based on both criteria (fill percentage AND initial intensity check)
                    is_marked = (fill_percentage >= min_fill_percentage_threshold) and is_potentially_marked_by_intensity
                    
                    print(f"  Q{q_num}{option_letter}: Fill={fill_percentage:.2f}, MeanIntensity={mean_intensity:.1f}, "
                          f"PotentiallyMarkedByIntensity={is_potentially_marked_by_intensity}, IsMarked={is_marked}")

                    # Save individual option images and their thresholded versions
                    # Use current_option_crops_dir here
                    vis_roi = option_img_roi.copy()
                    cx, cy, r = circle_coords
                    if circle_found and r > 0:
                        cv2.circle(vis_roi, (cx, cy), r, (0, 255, 0), 1) # Green circle
                    elif not circle_found: # Draw a red rectangle for the fallback square region
                        h, w = option_img_roi.shape[:2]
                        square_side = min(h, w)
                        x_start = (w - square_side) // 2
                        y_start = (h - square_side) // 2
                        cv2.rectangle(vis_roi, (x_start, y_start), (x_start + square_side, y_start + square_side), (0, 0, 255), 1)

                    option_crop_filename = os.path.join(current_option_crops_dir, # Changed path
                                                        f"Q{q_num}{option_letter}_meanI_{mean_intensity:.1f}_fill_{fill_percentage:.2f}.jpg")
                    cv2.imwrite(option_crop_filename, vis_roi)

                    # Save the cleaned-up thresholded image
                    thresh_crop_filename = os.path.join(current_option_crops_dir, # Changed path
                                                        f"Q{q_num}{option_letter}_thresh_cleaned.jpg")
                    cv2.imwrite(thresh_crop_filename, thresh_img)


                    # Prepare text for visualization on the main image
                    display_text = f"{option_letter}: {fill_percentage:.2f} ({mean_intensity:.1f})"
                    text_color = (0, 0, 255) # Red for unmarked
                    
                    if is_marked:
                        marked_options_for_q.append(option_letter)
                        cv2.rectangle(image_with_marked_overlays, (x1, y1), (x2, y2), (0, 255, 0), 2) # Green for marked
                        text_color = (0, 255, 0) # Green text for marked
                        display_text += " MARKED"
                    else:
                        cv2.rectangle(image_with_marked_overlays, (x1, y1), (x2, y2), (0, 0, 255), 1) # Red for unmarked, thinner line

                    text_x = x1
                    text_y = y1 - 5
                    if text_y < 0: text_y = y1 + 15
                    if text_x < 0: text_x = 0
                    
                    cv2.putText(image_with_marked_overlays, display_text, (text_x, text_y), 
                                cv2.FONT_HERSHEY_SIMPLEX, 0.4, text_color, 1)
            
            results[q_num] = marked_options_for_q

            # --- Review Logic ---
            if len(marked_options_for_q) != 1:
                print(f"  Q{q_num} requires review (Marked: {len(marked_options_for_q)}).")
                self._save_for_review(q_num, name_without_ext, questions_bboxes)
            # --- End Review Logic ---

        marked_overlay_filename = os.path.join(self.marked_superimposed_dir, os.path.basename(self.image_path))
        cv2.imwrite(marked_overlay_filename, image_with_marked_overlays)

        return results

def process_marked_options_folder(folder_path, mapped_annotations_path, output_base_dir):
    with open(mapped_annotations_path, 'r') as f:
        all_mapped_annotations_data = json.load(f)

    # Ensure the base marked_results directory exists
    marked_output_dir = os.path.join(output_base_dir, "marked_results")
    os.makedirs(marked_output_dir, exist_ok=True)

    final_results = {}

    for filename in os.listdir(folder_path):
        if filename.lower().endswith((".jpg", ".jpeg", ".png")):
            deskewed_image_dir = f"annotate_{os.path.basename(folder_path.rstrip('/\\'))}"
            deskewed_image_path = os.path.join(output_base_dir, deskewed_image_dir, filename)
            
            print(f"\nDetecting marked options for {deskewed_image_path}...")

            if not os.path.exists(deskewed_image_path):
                print(f"Skipping {filename}: Deskewed image not found at {deskewed_image_path}. Make sure optionMapping.py ran successfully.")
                continue

            if filename not in all_mapped_annotations_data:
                print(f"Skipping {filename}: Mapped annotations not found.")
                continue

            image_mapped_annotations = all_mapped_annotations_data[filename]
            
            try:
                detector = MarkedOptionDetector(deskewed_image_path, image_mapped_annotations, marked_output_dir)
                # Recommended starting thresholds. Tune based on output.
                marked_options_per_q = detector.detect_marked_options(
                    min_fill_percentage_threshold=0.35, # Tune this based on your image analysis
                    min_pixel_intensity_threshold=90    # Tune this based on your image analysis
                ) 
                final_results[filename] = marked_options_per_q

                print(f"\nResults for {filename}:")
                for q_num in sorted(marked_options_per_q.keys()):
                    marked = marked_options_per_q[q_num]
                    if marked:
                        print(f"  Q{q_num}: {', '.join(marked)}")
                    else:
                        print(f"  Q{q_num}: (No option marked)")

            except Exception as e:
                print(f"Error detecting marked options for {filename}: {e}")
                error_img_path = os.path.join(marked_output_dir, "warnings")
                os.makedirs(error_img_path, exist_ok=True)
                cv2.imwrite(os.path.join(error_img_path, filename), cv2.imread(deskewed_image_path))


    final_results_json_path = os.path.join(marked_output_dir, "marked_options_summary.json")
    with open(final_results_json_path, 'w') as f:
        json.dump(final_results, f, indent=2)
    print(f"\nSummary of marked options saved to {final_results_json_path}")

if __name__ == "__main__":
    folder_path = r"D:\Projects\OMR\new_abhigyan\Phase1\testData\BE23_Series" 
    mapped_annotations_path = r"D:\Projects\OMR\new_abhigyan\Phase2\annotate_BE23_Series\mapped_annotations.json" 
    output_base_dir = r"D:\Projects\OMR\new_abhigyan\Phase2" 

    process_marked_options_folder(folder_path, mapped_annotations_path, output_base_dir)
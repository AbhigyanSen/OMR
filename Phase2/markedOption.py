import cv2
import numpy as np
import os
import json
import re

class MarkedOptionDetector:
    def __init__(self, image_path, mapped_annotations_data, output_dir):
        self.image_path = image_path
        self.image = cv2.imread(image_path) 
        if self.image is None:
            raise FileNotFoundError(f"Image not found at {image_path}. Ensure this is the deskewed image generated by optionMapping.py.")
        
        self.mapped_annotations = mapped_annotations_data
        self.output_dir = output_dir

        self.option_crops_dir = os.path.join(self.output_dir, "option_crops")
        os.makedirs(self.option_crops_dir, exist_ok=True)

        self.marked_superimposed_dir = os.path.join(self.output_dir, "marked_superimposed")
        os.makedirs(self.marked_superimposed_dir, exist_ok=True)


    def _extract_question_option_bboxes(self):
        questions = {}
        options = {}

        for class_name, bbox in self.mapped_annotations.items():
            match_q = re.match(r'Q(\d+)', class_name)
            match_opt = re.match(r'(\d+)([A-D])', class_name)

            if match_q:
                q_num = int(match_q.group(1))
                questions[q_num] = bbox
            elif match_opt:
                q_num = int(match_opt.group(1))
                option_letter = match_opt.group(2)
                if q_num not in options:
                    options[q_num] = {}
                options[q_num][option_letter] = bbox
        
        for q_num in options:
            options[q_num] = dict(sorted(options[q_num].items()))

        return questions, options

    # --- REFINED MARKED PERCENTAGE DETECTION WITH ROBUST CIRCLE EXTRACTION ---
    def _get_marked_data_from_circle(self, option_img_roi, min_pixel_intensity_threshold=90): # Default back to 90 for mean intensity
        gray_option = cv2.cvtColor(option_img_roi, cv2.COLOR_BGR2GRAY)
        blurred = cv2.GaussianBlur(gray_option, (5, 5), 0)

        # Attempt to find circles with more forgiving parameters
        min_dim = min(option_img_roi.shape[0], option_img_roi.shape[1])
        min_r_estimate = int(min_dim * 0.3)
        max_r_estimate = int(min_dim * 0.45)
        
        # Use slightly adjusted HoughCircles parameters
        # dp: Increase if circles are still not found, but can lead to false positives. 1.0 is highest resolution.
        # minDist: Can be made smaller if circles are very close.
        # param1: Higher for stronger edges.
        # param2: Lower for more circles (more false positives but fewer misses). Try from 20-30.
        circles = cv2.HoughCircles(blurred, cv2.HOUGH_GRADIENT, dp=1.0, minDist=min_dim // 4, # Smaller minDist
                                   param1=100, param2=20, # Reduced param2
                                   minRadius=min_r_estimate, maxRadius=max_r_estimate)

        circle_mask = np.zeros_like(gray_option)
        center_x, center_y, radius = -1, -1, -1 # Default values if no circle found
        detected_circle = False

        if circles is not None:
            circles = np.uint16(np.around(circles))
            largest_circle = None
            max_radius = 0
            for i in circles[0, :]:
                # Filter out circles too close to the border or too small
                # This helps prevent finding the bounding box edges as circles
                if i[2] > max_radius and \
                   i[0] - i[2] >= 0 and i[0] + i[2] < option_img_roi.shape[1] and \
                   i[1] - i[2] >= 0 and i[1] + i[2] < option_img_roi.shape[0]:
                    max_radius = i[2]
                    largest_circle = i
            
            if largest_circle is not None:
                center_x, center_y, radius = largest_circle[0], largest_circle[1], largest_circle[2]
                cv2.circle(circle_mask, (center_x, center_y), radius, 255, -1)
                detected_circle = True

        if not detected_circle:
            print("Warning: No prominent circle found. Analyzing entire ROI.")
            # Fallback: if no circle, use the central square region of the ROI as the effective area
            # This is better than the entire rectangle for fill percentage
            h, w = gray_option.shape
            square_side = min(h, w)
            x_start = (w - square_side) // 2
            y_start = (h - square_side) // 2
            circle_mask[y_start : y_start + square_side, x_start : x_start + square_side] = 255
            # For visualization, pretend a circle centered in this square was found
            center_x, center_y = w // 2, h // 2
            radius = square_side // 2

        # Apply the mask to the blurred grayscale image
        masked_region = cv2.bitwise_and(blurred, blurred, mask=circle_mask)
        
        pixels_in_mask = masked_region[circle_mask == 255]
        
        if pixels_in_mask.size == 0:
            return 0.0, np.zeros_like(blurred), 255.0, False, (center_x, center_y, radius), detected_circle

        mean_intensity = np.mean(pixels_in_mask)
        is_potentially_marked_by_intensity = mean_intensity < min_pixel_intensity_threshold
        
        # --- Robust Binarization for Fill Percentage ---
        # Instead of relying solely on Otsu on the masked region, let's use the overall ROI for thresholding
        # And then apply the mask. This can sometimes give a better global threshold.
        # Alternative: use a fixed threshold or adaptive threshold on the masked region if Otsu struggles.
        
        # Let's try Otsu on the original blurred ROI, then apply mask.
        # This gives a threshold that considers the full range of pixel values in the box.
        _, global_thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        
        # Apply the circle mask to this global threshold
        thresh_binary_masked = cv2.bitwise_and(global_thresh, global_thresh, mask=circle_mask)

        # Morphological operations to clean up
        kernel = np.ones((3,3), np.uint8) 
        thresh_eroded = cv2.erode(thresh_binary_masked, kernel, iterations=1)
        thresh_dilated = cv2.dilate(thresh_eroded, kernel, iterations=2) 
        
        # The final thresholded image used for counting. Ensure it's within the mask.
        thresh_final = cv2.bitwise_and(thresh_dilated, thresh_dilated, mask=circle_mask)

        marked_pixels_count = cv2.countNonZero(thresh_final)
        total_mask_pixels = cv2.countNonZero(circle_mask)

        fill_percentage = 0.0
        if total_mask_pixels > 0:
            fill_percentage = marked_pixels_count / total_mask_pixels

        return fill_percentage, thresh_final, mean_intensity, is_potentially_marked_by_intensity, (center_x, center_y, radius), detected_circle
    # --- END REFINED MARKED PERCENTAGE DETECTION ---


    def detect_marked_options(self, min_fill_percentage_threshold=0.35, min_pixel_intensity_threshold=90): # Adjusted default thresholds
        questions_bboxes, options_bboxes = self._extract_question_option_bboxes()
        results = {}
        
        image_with_marked_overlays = self.image.copy()

        print("\n--- Option Analysis ---")
        print(f"Global min_fill_percentage_threshold: {min_fill_percentage_threshold:.2f}")
        print(f"Global min_pixel_intensity_threshold: {min_pixel_intensity_threshold:.1f}\n")


        for q_num in sorted(questions_bboxes.keys()): # Iterate through questions to ensure order
            marked_options_for_q = []
            
            if q_num in options_bboxes:
                for option_letter, bbox in options_bboxes[q_num].items():
                    x1, y1, x2, y2 = bbox
                    
                    x1 = max(0, x1)
                    y1 = max(0, y1)
                    x2 = min(self.image.shape[1], x2)
                    y2 = min(self.image.shape[0], y2)

                    if x2 <= x1 or y2 <= y1:
                        print(f"Warning: Invalid bounding box for {q_num}{option_letter}: {bbox}. Skipping.")
                        continue

                    option_img_roi = self.image[y1:y2, x1:x2]

                    if option_img_roi.size == 0:
                        print(f"Warning: Empty ROI for {q_num}{option_letter}. Skipping.")
                        continue

                    # Call the refined detection function
                    fill_percentage, thresh_img, mean_intensity, is_potentially_marked_by_intensity, circle_coords, circle_found = \
                        self._get_marked_data_from_circle(option_img_roi, min_pixel_intensity_threshold)
                    
                    # Determine if marked based on both criteria (fill percentage AND initial intensity check)
                    is_marked = (fill_percentage >= min_fill_percentage_threshold) and is_potentially_marked_by_intensity
                    
                    print(f"  Q{q_num}{option_letter}: Fill={fill_percentage:.2f}, MeanIntensity={mean_intensity:.1f}, "
                          f"PotentiallyMarkedByIntensity={is_potentially_marked_by_intensity}, IsMarked={is_marked}")

                    # Save individual option images and their thresholded versions
                    base_filename = os.path.basename(self.image_path)
                    name_without_ext = os.path.splitext(base_filename)[0]
                    
                    # Highlight the detected circle (or square fallback) on the original crop for debugging
                    vis_roi = option_img_roi.copy()
                    cx, cy, r = circle_coords
                    if circle_found and r > 0:
                        cv2.circle(vis_roi, (cx, cy), r, (0, 255, 0), 1) # Green circle
                    elif not circle_found: # Draw a red rectangle for the fallback square region
                        h, w = option_img_roi.shape[:2]
                        square_side = min(h, w)
                        x_start = (w - square_side) // 2
                        y_start = (h - square_side) // 2
                        cv2.rectangle(vis_roi, (x_start, y_start), (x_start + square_side, y_start + square_side), (0, 0, 255), 1)

                    option_crop_filename = os.path.join(self.option_crops_dir, 
                                                        f"{name_without_ext}_Q{q_num}{option_letter}_meanI_{mean_intensity:.1f}_fill_{fill_percentage:.2f}.jpg")
                    cv2.imwrite(option_crop_filename, vis_roi)

                    # Save the cleaned-up thresholded image
                    thresh_crop_filename = os.path.join(self.option_crops_dir, 
                                                        f"{name_without_ext}_Q{q_num}{option_letter}_thresh_cleaned.jpg")
                    cv2.imwrite(thresh_crop_filename, thresh_img)


                    # Prepare text for visualization on the main image
                    # display_text = f"{option_letter}: {fill_percentage:.2f} ({mean_intensity:.1f})"
                    display_text = f"    {fill_percentage:.2f}"
                    text_color = (0, 0, 255) # Red for unmarked
                    
                    if is_marked:
                        marked_options_for_q.append(option_letter)
                        cv2.rectangle(image_with_marked_overlays, (x1, y1), (x2, y2), (0, 255, 0), 2) # Green for marked
                        text_color = (0, 255, 0) # Green text for marked
                        # display_text += " MARKED"
                    else:
                        cv2.rectangle(image_with_marked_overlays, (x1, y1), (x2, y2), (0, 0, 255), 1) # Red for unmarked, thinner line

                    text_x = x1
                    text_y = y1 - 5
                    if text_y < 0: text_y = y1 + 15
                    if text_x < 0: text_x = 0
                    
                    cv2.putText(image_with_marked_overlays, display_text, (text_x, text_y), 
                                cv2.FONT_HERSHEY_SIMPLEX, 0.4, text_color, 1)
            
            results[q_num] = marked_options_for_q
        
        marked_overlay_filename = os.path.join(self.marked_superimposed_dir, os.path.basename(self.image_path))
        cv2.imwrite(marked_overlay_filename, image_with_marked_overlays)

        return results

def process_marked_options_folder(folder_path, mapped_annotations_path, output_base_dir):
    with open(mapped_annotations_path, 'r') as f:
        all_mapped_annotations_data = json.load(f)

    marked_output_dir = os.path.join(output_base_dir, "marked_results")
    os.makedirs(marked_output_dir, exist_ok=True)

    final_results = {}

    for filename in os.listdir(folder_path):
        if filename.lower().endswith((".jpg", ".jpeg", ".png")):
            deskewed_image_dir = f"options_{os.path.basename(folder_path.rstrip('/\\'))}"
            deskewed_image_path = os.path.join(output_base_dir, deskewed_image_dir, filename)
            
            print(f"\nDetecting marked options for {deskewed_image_path}...")

            if not os.path.exists(deskewed_image_path):
                print(f"Skipping {filename}: Deskewed image not found at {deskewed_image_path}. Make sure optionMapping.py ran successfully.")
                continue

            if filename not in all_mapped_annotations_data:
                print(f"Skipping {filename}: Mapped annotations not found.")
                continue

            image_mapped_annotations = all_mapped_annotations_data[filename]
            
            try:
                detector = MarkedOptionDetector(deskewed_image_path, image_mapped_annotations, marked_output_dir)
                # Recommended starting thresholds. Tune based on output.
                marked_options_per_q = detector.detect_marked_options(
                    min_fill_percentage_threshold=0.35, # Reduced for more flexibility, will tune with new fill values
                    min_pixel_intensity_threshold=90    # Retained, as this looked promising for dark areas
                ) 
                final_results[filename] = marked_options_per_q

                print(f"\nResults for {filename}:")
                for q_num in sorted(marked_options_per_q.keys()):
                    marked = marked_options_per_q[q_num]
                    if marked:
                        print(f"  Q{q_num}: {', '.join(marked)}")
                    else:
                        print(f"  Q{q_num}: (No option marked)")

            except Exception as e:
                print(f"Error detecting marked options for {filename}: {e}")
                error_img_path = os.path.join(marked_output_dir, "warnings")
                os.makedirs(error_img_path, exist_ok=True)
                cv2.imwrite(os.path.join(error_img_path, filename), cv2.imread(deskewed_image_path))


    final_results_json_path = os.path.join(marked_output_dir, "marked_options_summary.json")
    with open(final_results_json_path, 'w') as f:
        json.dump(final_results, f, indent=2)
    print(f"\nSummary of marked options saved to {final_results_json_path}")

if __name__ == "__main__":
    folder_path = r"D:\Projects\OMR\new_abhigyan\Phase1\testData\Option_Checking" 
    mapped_annotations_path = r"D:\Projects\OMR\new_abhigyan\Phase2\options_Option_Checking\mapped_annotations.json" 
    output_base_dir = r"D:\Projects\OMR\new_abhigyan\Phase2" 

    process_marked_options_folder(folder_path, mapped_annotations_path, output_base_dir)
import cv2
import numpy as np
import os
import json

class OptionMapper:
    def __init__(self, image_path, annotations_path, classes_path, anchor_data):
        self.image_path = image_path
        self.annotations_path = annotations_path
        self.classes_path = classes_path
        
        self.anchor_data = anchor_data # This now contains 'anchors', 'M_transform', 'deskewed_width', 'deskewed_height'
        
        self.original_image = cv2.imread(image_path) # Keep original for loading annotations
        if self.original_image is None:
            raise FileNotFoundError(f"Image not found at {image_path}")
            
        self.original_height, self.original_width = self.original_image.shape[:2]
        self.classes = self._load_classes()
        self.annotations = self._load_annotations() # Annotations are still in original coordinates

        # Load the deskewed image and M_transform
        # For simplicity, we'll assume anchorDetection already saved the deskewed image
        # or we re-deskew it here. Re-deskewing is safer for independent runs.
        # However, to maintain the deskewed image generated by anchorDetection,
        # it's best to pass it directly if the scripts run sequentially.
        # For a more robust solution, the deskewed image should ideally be loaded or generated here.
        # Given your current setup, we'll assume the image passed to OptionMapper
        # will eventually be the deskewed one or we will apply the transform.

        # We need the transformation matrix to convert original annotation coordinates
        self.M_transform = np.array(self.anchor_data.get("M_transform")) if self.anchor_data.get("M_transform") else None
        self.deskewed_width = self.anchor_data.get("deskewed_width", self.original_width)
        self.deskewed_height = self.anchor_data.get("deskewed_height", self.original_height)

        # The image that we will draw on should be the deskewed one.
        # Let's re-deskew the image here using the stored M_transform.
        if self.M_transform is not None:
            self.image = cv2.warpPerspective(self.original_image, self.M_transform, (self.deskewed_width, self.deskewed_height))
        else:
            self.image = self.original_image.copy() # If no deskewing, just use the original image copy


    def _load_classes(self):
        with open(self.classes_path, 'r') as f:
            return [line.strip() for line in f.readlines()]

    def _load_annotations(self):
        annotations = []
        with open(self.annotations_path, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) == 5:
                    class_id = int(parts[0])
                    # Store normalized coordinates
                    norm_x_center = float(parts[1])
                    norm_y_center = float(parts[2])
                    norm_width = float(parts[3])
                    norm_height = float(parts[4])
                    annotations.append((self.classes[class_id], norm_x_center, norm_y_center, norm_width, norm_height))
        return annotations
    
    def map_and_draw(self):
        # The reference anchor (Anch1) center in the *deskewed* image
        ref_x, ref_y = self.anchor_data["anchors"]["Anch1"]

        for class_name, norm_x_center, norm_y_center, norm_width, norm_height in self.annotations:
            if "Anch" in class_name:
                continue

            # Convert normalized original coordinates to pixel original coordinates
            original_x_center = norm_x_center * self.original_width
            original_y_center = norm_y_center * self.original_height
            original_width_px = norm_width * self.original_width
            original_height_px = norm_height * self.original_height

            # Calculate original bounding box corners
            original_x1 = original_x_center - original_width_px / 2
            original_y1 = original_y_center - original_height_px / 2
            original_x2 = original_x_center + original_width_px / 2
            original_y2 = original_y_center + original_height_px / 2

            if self.M_transform is not None:
                # Transform the original bounding box corners to the deskewed image space
                original_pts = np.float32([
                    [original_x1, original_y1], [original_x2, original_y1],
                    [original_x2, original_y2], [original_x1, original_y2]
                ]).reshape(-1, 1, 2)
                transformed_pts = cv2.perspectiveTransform(original_pts, self.M_transform).reshape(-1, 2)

                # Get the new bounding box in the deskewed image
                new_x1 = int(np.min(transformed_pts[:, 0]))
                new_y1 = int(np.min(transformed_pts[:, 1]))
                new_x2 = int(np.max(transformed_pts[:, 0]))
                new_y2 = int(np.max(transformed_pts[:, 1]))
            else:
                # If no deskewing, use original coordinates as is
                new_x1, new_y1, new_x2, new_y2 = int(original_x1), int(original_y1), int(original_x2), int(original_y2)

            cv2.rectangle(self.image, (new_x1, new_y1), (new_x2, new_y2), (0, 255, 0), 2)
            cv2.putText(self.image, class_name, (new_x1, new_y1 - 5),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 0), 2)

        return self.image

def process_folder(folder_path, annotations_file, classes_file, anchor_centers_path):
    folder_name = os.path.basename(folder_path.rstrip("\\/"))
    output_dir = f"options_{folder_name}"
    warning_dir = os.path.join(output_dir, "warnings")
    os.makedirs(output_dir, exist_ok=True)
    os.makedirs(warning_dir, exist_ok=True)

    with open(anchor_centers_path, "r") as f:
        all_anchor_data = json.load(f) # Load all data

    for filename in os.listdir(folder_path):
        if filename.lower().endswith((".jpg", ".jpeg", ".png")):
            image_path = os.path.join(folder_path, filename)
            print(f"\nProcessing {image_path}...")

            try:
                if filename not in all_anchor_data:
                    raise Exception("Anchor data not found for this image.")
                
                image_specific_anchor_data = all_anchor_data[filename]

                mapper = OptionMapper(image_path, annotations_file, classes_file, image_specific_anchor_data)
                mapped_image = mapper.map_and_draw()

                save_path = os.path.join(output_dir, filename)
                cv2.imwrite(save_path, mapped_image)
                print(f"Mapped and saved to {save_path}")

            except Exception as e:
                print(f"Error processing {filename}: {e}")
                warning_path = os.path.join(warning_dir, filename)
                # Save the original image to warnings if processing fails
                cv2.imwrite(warning_path, cv2.imread(image_path)) 
                print(f"Saved to warning folder: {warning_path}")

if __name__ == "__main__":
    folder_path = r"D:\Projects\OMR\new_abhigyan\Phase1\testData\Option_Checking"
    annotations_file = r"D:\Projects\OMR\new_abhigyan\Phase1\Options\BE23-01-01003.txt"
    classes_file = r"D:\Projects\OMR\new_abhigyan\Phase1\Options\classes.txt"
    # Ensure this path is correct after anchorDetection.py runs
    anchor_centers_path = r"D:\Projects\OMR\new_abhigyan\Phase2\output_Option_Checking\anchor_centers.json" 

    process_folder(folder_path, annotations_file, classes_file, anchor_centers_path)
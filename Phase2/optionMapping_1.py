import cv2
import numpy as np
import os
import json

class OptionMapper:
    def __init__(self, image_path, annotations_path, classes_path, anchor_data):
        self.image_path = image_path
        self.annotations_path = annotations_path
        self.classes_path = classes_path
        
        self.anchor_data = anchor_data
        
        self.original_image = cv2.imread(image_path)                                    # Keep original for loading annotations
        if self.original_image is None:
            raise FileNotFoundError(f"Image not found at {image_path}")
            
        self.original_height, self.original_width = self.original_image.shape[:2]
        self.classes = self._load_classes()
        self.annotations = self._load_annotations()                                     # Annotations are still in original coordinates

        '''
        Load the deskewed image and M_transform
        For simplicity, we'll assume anchorDetection already saved the deskewed image
        or we re-deskew it here. Re-deskewing is safer for independent runs.
        However, to maintain the deskewed image generated by anchorDetection,
        it's best to pass it directly if the scripts run sequentially.
        For a more robust solution, the deskewed image should ideally be loaded or generated here.
        Given your current setup, we'll assume the image passed to OptionMapper
        will eventually be the deskewed one or we will apply the transform.
        '''

        # We need the transformation matrix to convert original annotation coordinates
        self.M_transform = np.array(self.anchor_data.get("M_transform")) if self.anchor_data.get("M_transform") else None
        self.deskewed_width = self.anchor_data.get("deskewed_width", self.original_width)
        self.deskewed_height = self.anchor_data.get("deskewed_height", self.original_height)

        # The image that we will draw on should be the deskewed one.
        # Let's re-deskew the image here using the stored M_transform.
        if self.M_transform is not None:
            self.image = cv2.warpPerspective(self.original_image, self.M_transform, (self.deskewed_width, self.deskewed_height))
        else:
            self.image = self.original_image.copy() # If no deskewing, just use the original image copy


    def _load_classes(self):
        with open(self.classes_path, 'r') as f:
            return [line.strip() for line in f.readlines()]

    def _load_annotations(self):
        annotations = []
        with open(self.annotations_path, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) == 5:
                    class_id = int(parts[0])
                    # Store normalized coordinates
                    norm_x_center = float(parts[1])
                    norm_y_center = float(parts[2])
                    norm_width = float(parts[3])
                    norm_height = float(parts[4])
                    annotations.append((self.classes[class_id], norm_x_center, norm_y_center, norm_width, norm_height))
        return annotations
    
    def map_and_draw(self):
        # The reference anchor (Anch1) center in the DESKEWED image
        ref_x, ref_y = self.anchor_data["anchors"]["Anch1"]

        for class_name, norm_x_center, norm_y_center, norm_width, norm_height in self.annotations:
            if "Anch" in class_name:
                continue

            # Convert normalized original coordinates to pixel original coordinates
            original_x_center = norm_x_center * self.original_width
            original_y_center = norm_y_center * self.original_height
            original_width_px = norm_width * self.original_width
            original_height_px = norm_height * self.original_height

            # Calculate original bounding box corners
            original_x1 = original_x_center - original_width_px / 2
            original_y1 = original_y_center - original_height_px / 2
            original_x2 = original_x_center + original_width_px / 2
            original_y2 = original_y_center + original_height_px / 2

            if self.M_transform is not None:
                # Transform the original bounding box corners to the deskewed image space
                original_pts = np.float32([
                    [original_x1, original_y1], [original_x2, original_y1],
                    [original_x2, original_y2], [original_x1, original_y2]
                ]).reshape(-1, 1, 2)
                transformed_pts = cv2.perspectiveTransform(original_pts, self.M_transform).reshape(-1, 2)

                # Get the new bounding box in the deskewed image
                new_x1 = int(np.min(transformed_pts[:, 0]))
                new_y1 = int(np.min(transformed_pts[:, 1]))
                new_x2 = int(np.max(transformed_pts[:, 0]))
                new_y2 = int(np.max(transformed_pts[:, 1]))
            else:
                # If no deskewing, use original coordinates as is
                new_x1, new_y1, new_x2, new_y2 = int(original_x1), int(original_y1), int(original_x2), int(original_y2)

            cv2.rectangle(self.image, (new_x1, new_y1), (new_x2, new_y2), (0, 255, 0), 2)
            cv2.putText(self.image, class_name, (new_x1, new_y1 - 5),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 0), 2)

        return self.image

def process_folder(folder_path, annotations_file, classes_file, anchor_centers_path):
    folder_name = os.path.basename(folder_path.rstrip("\\/"))
    output_dir = f"options_{folder_name}"
    warning_dir = os.path.join(output_dir, "warnings")
    os.makedirs(output_dir, exist_ok=True)
    os.makedirs(warning_dir, exist_ok=True)

    with open(anchor_centers_path, "r") as f:
        all_anchor_data = json.load(f) # Load all data

    for filename in os.listdir(folder_path):
        if filename.lower().endswith((".jpg", ".jpeg", ".png")):
            image_path = os.path.join(folder_path, filename)
            print(f"\nProcessing {image_path}...")

            try:
                if filename not in all_anchor_data:
                    raise Exception("Anchor data not found for this image.")
                
                image_specific_anchor_data = all_anchor_data[filename]

                mapper = OptionMapper(image_path, annotations_file, classes_file, image_specific_anchor_data)
                mapped_image = mapper.map_and_draw()

                save_path = os.path.join(output_dir, filename)
                cv2.imwrite(save_path, mapped_image)
                print(f"Mapped and saved to {save_path}")

            except Exception as e:
                print(f"Error processing {filename}: {e}")
                warning_path = os.path.join(warning_dir, filename)
                # Save the original image to warnings if processing fails
                cv2.imwrite(warning_path, cv2.imread(image_path)) 
                print(f"Saved to warning folder: {warning_path}")

if __name__ == "__main__":
    folder_path = r"D:\Projects\OMR\new_abhigyan\Phase1\testData\Option_Checking"
    annotations_file = r"D:\Projects\OMR\new_abhigyan\Phase1\Options\BE23-01-01003.txt"
    classes_file = r"D:\Projects\OMR\new_abhigyan\Phase1\Options\classes.txt"
    
    # Path to the anchor centers JSON file created after anchorDetection.py
    anchor_centers_path = r"D:\Projects\OMR\new_abhigyan\Phase2\output_Option_Checking\anchor_centers.json" 

    process_folder(folder_path, annotations_file, classes_file, anchor_centers_path)